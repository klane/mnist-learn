{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..', '..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils import get_strategy, save_images, Timer\n",
    "\n",
    "tfl = tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'TensorFlow version: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = get_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    (X_train, _), (X_test, _) = tf.keras.datasets.mnist.load_data()\n",
    "    \n",
    "    # stack train and test images\n",
    "    X = np.vstack((X_train, X_test))\n",
    "    \n",
    "    # add channel to images (required by tensorflow)\n",
    "    X = np.expand_dims(X, axis=-1)\n",
    "    \n",
    "    # convert images to floats\n",
    "    X = X.astype('float32')\n",
    "    \n",
    "    # normalize images to [-1,1]\n",
    "    X = X / 127.5 - 1\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = load_data()\n",
    "\n",
    "BUFFER_SIZE = train_images.shape[0]\n",
    "BATCH_SIZE = 256 * strategy.num_replicas_in_sync\n",
    "\n",
    "IMAGE_SHAPE = train_images.shape[1:]\n",
    "LATENT_DIM = 100\n",
    "\n",
    "# batch and shuffle the data\n",
    "train_data = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Sequential):\n",
    "    def __init__(self, image_shape, latent_dim, first_layer_channels=256):\n",
    "        first_layer_rows = image_shape[0] // 4\n",
    "        first_layer_cols = image_shape[1] // 4\n",
    "        first_layer_shape=(first_layer_rows, first_layer_cols, first_layer_channels)\n",
    "        \n",
    "        super(Generator, self).__init__([\n",
    "            tfl.InputLayer(input_shape=(latent_dim,)),\n",
    "\n",
    "            tfl.Dense(np.prod(first_layer_shape), use_bias=False),\n",
    "            tfl.BatchNormalization(),\n",
    "            tfl.LeakyReLU(),\n",
    "            tfl.Reshape(first_layer_shape),\n",
    "\n",
    "            tfl.Conv2DTranspose(128, kernel_size=5, strides=1, padding='same', use_bias=False),\n",
    "            tfl.BatchNormalization(),\n",
    "            tfl.LeakyReLU(),\n",
    "\n",
    "            tfl.Conv2DTranspose(64, kernel_size=5, strides=2, padding='same', use_bias=False),\n",
    "            tfl.BatchNormalization(),\n",
    "            tfl.LeakyReLU(),\n",
    "\n",
    "            tfl.Conv2DTranspose(1, kernel_size=5, strides=2, padding='same', use_bias=False, activation='tanh')\n",
    "        ], name='Generator')\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "    \n",
    "    def sample(self, samples=1, training=False):\n",
    "        latent = tf.random.normal([samples, self.latent_dim])\n",
    "        return self(latent, training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator(image_shape):\n",
    "    return tf.keras.Sequential([\n",
    "        tfl.InputLayer(input_shape=image_shape),\n",
    "\n",
    "        tfl.Conv2D(64, kernel_size=5, strides=2, padding='same'),\n",
    "        tfl.LeakyReLU(),\n",
    "        tfl.Dropout(0.3),\n",
    "\n",
    "        tfl.Conv2D(128, kernel_size=5, strides=2, padding='same'),\n",
    "        tfl.LeakyReLU(),\n",
    "        tfl.Dropout(0.3),\n",
    "\n",
    "        tfl.Flatten(),\n",
    "        tfl.Dense(1)\n",
    "    ], name='Discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(object):\n",
    "    def __init__(self, generator, discriminator, generator_optimizer, discriminator_optimizer):\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.gen_opt = generator_optimizer\n",
    "        self.disc_opt = discriminator_optimizer\n",
    "        self.cross_entropy = tf.losses.BinaryCrossentropy(from_logits=True)\n",
    "        self.accuracy = tf.metrics.BinaryAccuracy()\n",
    "    \n",
    "    def train(self, images):\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            generated_images = self.generator.sample(BATCH_SIZE, training=True)\n",
    "\n",
    "            real_output = self.discriminator(images, training=True)\n",
    "            fake_output = self.discriminator(generated_images, training=True)\n",
    "\n",
    "            real_y = tf.ones_like(real_output)\n",
    "            fake_y = tf.zeros_like(fake_output)\n",
    "            \n",
    "            real_loss = self.cross_entropy(real_y, real_output)\n",
    "            fake_loss = self.cross_entropy(fake_y, fake_output)\n",
    "\n",
    "            gen_loss = self.cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "            disc_loss = real_loss + fake_loss\n",
    "\n",
    "        gen_grad = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
    "        disc_grad = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
    "\n",
    "        self.gen_opt.apply_gradients(zip(gen_grad, self.generator.trainable_variables))\n",
    "        self.disc_opt.apply_gradients(zip(disc_grad, self.discriminator.trainable_variables))\n",
    "        \n",
    "        self.accuracy.reset_states()\n",
    "        real_acc = self.accuracy(real_y, real_output)\n",
    "        \n",
    "        self.accuracy.reset_states()\n",
    "        fake_acc = self.accuracy(fake_y, fake_output)\n",
    "        \n",
    "        return gen_loss, disc_loss, real_acc, fake_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    generator = Generator(IMAGE_SHAPE, LATENT_DIM)\n",
    "    discriminator = make_discriminator(IMAGE_SHAPE)\n",
    "    gen_opt = tf.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    disc_opt = tf.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    gan = GAN(generator, discriminator, gen_opt, disc_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_image = generator.sample()\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, epochs, print_interval=10):\n",
    "    timer = Timer()\n",
    "    timer.start()\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        timer.split()\n",
    "\n",
    "        for batch, image_batch in dataset.enumerate(start=1):\n",
    "            gen_loss, disc_loss, real_acc, fake_acc = model.train(image_batch)\n",
    "            \n",
    "            if batch % print_interval == 0:\n",
    "                print(\n",
    "                    f'Epoch {epoch:04d}, Batch {batch:03d},',\n",
    "                    f'Loss: [G={gen_loss:.3f}, D={disc_loss:.3f}],',\n",
    "                    f'Acc: [real={real_acc*100:.2f}, fake={fake_acc*100:.2f}],',\n",
    "                    f'Time: [epoch={timer:%s}, total={timer:%e}]'\n",
    "                )\n",
    "\n",
    "        # save current digits generated from seed\n",
    "        images = model.generator(SEED, training=False)\n",
    "        save_images(images, epoch, IMAGE_DIR, PLOT_ROWS, PLOT_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = 'images'\n",
    "PLOT_ROWS = 5\n",
    "PLOT_COLS = 5\n",
    "\n",
    "# define seed used to plot images at each epoch\n",
    "SEED = tf.random.normal([PLOT_ROWS * PLOT_COLS, LATENT_DIM])\n",
    "\n",
    "# save initial \"digits\"\n",
    "%mkdir -p \"$IMAGE_DIR\"\n",
    "images = generator(SEED, training=False)\n",
    "save_images(images, 0, IMAGE_DIR, PLOT_ROWS, PLOT_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "train(gan, train_data, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import files\n",
    "except ImportError:\n",
    "    pass\n",
    "else:\n",
    "    files.download(IMAGE_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
